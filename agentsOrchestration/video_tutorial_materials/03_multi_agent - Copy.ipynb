{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field,ConfigDict\n",
    "\n",
    "from llama_index.core.tools import BaseTool\n",
    "\n",
    "class AgentConfig(BaseModel):\n",
    "    \"\"\"Used to configure an agent.\"\"\"\n",
    "\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "\n",
    "    name: str\n",
    "    description: str\n",
    "    system_prompt: str | None = None\n",
    "    tools: list[BaseTool] | None = None\n",
    "    tools_requiring_human_confirmation: list[str] = Field(default_factory=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "def add_two_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Used to add two numbers together.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "def multiply_two_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Used to multiply two numbers together.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "add_two_numbers_tool = FunctionTool.from_defaults(fn=add_two_numbers)\n",
    "multiply_two_numbers_tool = FunctionTool.from_defaults(fn=multiply_two_numbers)\n",
    "\n",
    "agent_config = AgentConfig(\n",
    "    name=\"Addition Agent\",\n",
    "    description=\"Used to add two numbers together.\",\n",
    "    system_prompt=\"You are an agent that adds two numbers together. Do not help the user with anything else.\",\n",
    "    tools=[add_two_numbers_tool],\n",
    "    tools_requiring_human_confirmation=[\"add_two_numbers\"],\n",
    ")\n",
    "\n",
    "agent_config_2 = AgentConfig(\n",
    "    name=\"Multiplication Agent\",\n",
    "    description=\"Used to multiply two numbers together.\",\n",
    "    system_prompt=\"You are an agent that multiplies two numbers together. Do not help the user with anything else.\",\n",
    "    tools=[multiply_two_numbers_tool],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_transfer() -> None:\n",
    "    \"\"\"Used to indicate that your job is done and you would like to transfer control to another agent.\"\"\"\n",
    "    pass\n",
    "\n",
    "def transfer_to_agent(agent_name: str) -> None: \n",
    "    \"\"\"Used to transfer the user to a specific agent.\"\"\"\n",
    "    pass\n",
    "\n",
    "request_transfer_tool = FunctionTool.from_defaults(fn=request_transfer)\n",
    "transfer_to_agent_tool = FunctionTool.from_defaults(fn=transfer_to_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T15:03:40.417766Z",
     "start_time": "2024-11-19T15:03:40.353238Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from llama_index.core.llms import ChatMessage, LLM\n",
    "from llama_index.core.program.function_program import get_function_tool\n",
    "from llama_index.core.tools import (\n",
    "    BaseTool,\n",
    "    ToolSelection,\n",
    ")\n",
    "from llama_index.core.workflow import (\n",
    "    Event,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    "    Context,\n",
    ")\n",
    "from llama_index.core.workflow.events import InputRequiredEvent, HumanResponseEvent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "\n",
    "class ActiveSpeakerEvent(Event):\n",
    "    pass\n",
    "\n",
    "\n",
    "class OrchestratorEvent(Event):\n",
    "    pass\n",
    "\n",
    "\n",
    "class ToolCallEvent(Event):\n",
    "    tool_call: ToolSelection\n",
    "    tools: list[BaseTool]\n",
    "\n",
    "\n",
    "class ToolCallResultEvent(Event):\n",
    "    chat_message: ChatMessage\n",
    "\n",
    "\n",
    "class ToolRequestEvent(InputRequiredEvent):\n",
    "    tool_name: str\n",
    "    tool_id: str\n",
    "    tool_kwargs: dict\n",
    "\n",
    "\n",
    "class ToolApprovedEvent(HumanResponseEvent):\n",
    "    tool_name: str\n",
    "    tool_id: str\n",
    "    tool_kwargs: dict\n",
    "    approved: bool\n",
    "    response: str | None = None\n",
    "\n",
    "\n",
    "class ProgressEvent(Event):\n",
    "    msg: str\n",
    "\n",
    "\n",
    "DEFAULT_ORCHESTRATOR_PROMPT = (\n",
    "    \"You are on orchestration agent.\\n\"\n",
    "    \"Your job is to decide which agent to run based on the current state of the user and what they've asked to do.\\n\"\n",
    "    \"You do not need to figure out dependencies between agents; the agents will handle that themselves.\\n\"\n",
    "    \"Here the the agents you can choose from:\\n{agent_context_str}\\n\\n\"\n",
    "    \"Here is the current user state:\\n{user_state_str}\\n\\n\"\n",
    "    \"Please assist the user and transfer them as needed.\"\n",
    ")\n",
    "DEFAULT_TOOL_REJECT_STR = \"The tool call was not approved, likely due to a mistake or preconditions not being met.\"\n",
    "\n",
    "\n",
    "class ConciergeAgent(Workflow):\n",
    "    def __init__(\n",
    "        self,\n",
    "        orchestrator_prompt: str | None = None,\n",
    "        default_tool_reject_str: str | None = None,\n",
    "        **kwargs: Any,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.orchestrator_prompt = orchestrator_prompt or DEFAULT_ORCHESTRATOR_PROMPT\n",
    "        self.default_tool_reject_str = (\n",
    "            default_tool_reject_str or DEFAULT_TOOL_REJECT_STR\n",
    "        )\n",
    "\n",
    "    @step\n",
    "    async def setup(\n",
    "        self, ctx: Context, ev: StartEvent\n",
    "    ) -> ActiveSpeakerEvent | OrchestratorEvent:\n",
    "        \"\"\"Sets up the workflow, validates inputs, and stores them in the context.\"\"\"\n",
    "        active_speaker = await ctx.get(\"active_speaker\", default=\"\")\n",
    "        user_msg = ev.get(\"user_msg\")\n",
    "        agent_configs = ev.get(\"agent_configs\", default=[])\n",
    "        llm: LLM = ev.get(\"llm\", default=OpenAI(model=\"gpt-4o\", temperature=0.3))\n",
    "        chat_history = ev.get(\"chat_history\", default=[])\n",
    "        initial_state = ev.get(\"initial_state\", default={})\n",
    "        if (\n",
    "            user_msg is None\n",
    "            or agent_configs is None\n",
    "            or llm is None\n",
    "            or chat_history is None\n",
    "        ):\n",
    "            raise ValueError(\n",
    "                \"User message, agent configs, llm, and chat_history are required!\"\n",
    "            )\n",
    "\n",
    "        if not llm.metadata.is_function_calling_model:\n",
    "            raise ValueError(\"LLM must be a function calling model!\")\n",
    "\n",
    "        # store the agent configs in the context\n",
    "        agent_configs_dict = {ac.name: ac for ac in agent_configs}\n",
    "        await ctx.set(\"agent_configs\", agent_configs_dict)\n",
    "        await ctx.set(\"llm\", llm)\n",
    "\n",
    "        chat_history.append(ChatMessage(role=\"user\", content=user_msg))\n",
    "        await ctx.set(\"chat_history\", chat_history)\n",
    "\n",
    "        await ctx.set(\"user_state\", initial_state)\n",
    "\n",
    "        # if there is an active speaker, we need to transfer forward the user to them\n",
    "        if active_speaker:\n",
    "            return ActiveSpeakerEvent()\n",
    "\n",
    "        # otherwise, we need to decide who the next active speaker is\n",
    "        return OrchestratorEvent(user_msg=user_msg)\n",
    "\n",
    "    @step\n",
    "    async def speak_with_agent(\n",
    "        self, ctx: Context, ev: ActiveSpeakerEvent\n",
    "    ) -> ToolCallEvent | ToolRequestEvent | StopEvent:\n",
    "        \"\"\"Speaks with the active sub-agent and handles tool calls (if any).\"\"\"\n",
    "        # Setup the agent for the active speaker\n",
    "        active_speaker = await ctx.get(\"active_speaker\")\n",
    "\n",
    "        agent_config: AgentConfig = (await ctx.get(\"agent_configs\"))[active_speaker]\n",
    "        chat_history = await ctx.get(\"chat_history\")\n",
    "        llm = await ctx.get(\"llm\")\n",
    "\n",
    "        user_state = await ctx.get(\"user_state\")\n",
    "        user_state_str = \"\\n\".join([f\"{k}: {v}\" for k, v in user_state.items()])\n",
    "        system_prompt = (\n",
    "            agent_config.system_prompt.strip()\n",
    "            + f\"\\n\\nHere is the current user state:\\n{user_state_str}\"\n",
    "        )\n",
    "\n",
    "        llm_input = [ChatMessage(role=\"system\", content=system_prompt)] + chat_history\n",
    "\n",
    "        # inject the request transfer tool into the list of tools\n",
    "        tools = [request_transfer_tool] + agent_config.tools\n",
    "\n",
    "        response = await llm.achat_with_tools(tools, chat_history=llm_input)\n",
    "\n",
    "        tool_calls: list[ToolSelection] = llm.get_tool_calls_from_response(\n",
    "            response, error_on_no_tool_call=False\n",
    "        )\n",
    "        if len(tool_calls) == 0:\n",
    "            chat_history.append(response.message)\n",
    "            await ctx.set(\"chat_history\", chat_history)\n",
    "            return StopEvent(\n",
    "                result={\n",
    "                    \"response\": response.message.content,\n",
    "                    \"chat_history\": chat_history,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        await ctx.set(\"num_tool_calls\", len(tool_calls))\n",
    "\n",
    "        for tool_call in tool_calls:\n",
    "            if tool_call.tool_name == request_transfer_tool.metadata.name:\n",
    "                await ctx.set(\"active_speaker\", None)\n",
    "                ctx.write_event_to_stream(\n",
    "                    ProgressEvent(msg=\"Agent is requesting a transfer. Please hold.\")\n",
    "                )\n",
    "                return OrchestratorEvent()\n",
    "            elif tool_call.tool_name in agent_config.tools_requiring_human_confirmation:\n",
    "                ctx.write_event_to_stream(\n",
    "                    ToolRequestEvent(\n",
    "                        prefix=f\"Tool {tool_call.tool_name} requires human approval.\",\n",
    "                        tool_name=tool_call.tool_name,\n",
    "                        tool_kwargs=tool_call.tool_kwargs,\n",
    "                        tool_id=tool_call.tool_id,\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                ctx.send_event(\n",
    "                    ToolCallEvent(tool_call=tool_call, tools=agent_config.tools)\n",
    "                )\n",
    "\n",
    "        chat_history.append(response.message)\n",
    "        await ctx.set(\"chat_history\", chat_history)\n",
    "\n",
    "    @step\n",
    "    async def handle_tool_approval(\n",
    "        self, ctx: Context, ev: ToolApprovedEvent\n",
    "    ) -> ToolCallEvent | ToolCallResultEvent:\n",
    "        \"\"\"Handles the approval or rejection of a tool call.\"\"\"\n",
    "        if ev.approved:\n",
    "            active_speaker = await ctx.get(\"active_speaker\")\n",
    "            agent_config = (await ctx.get(\"agent_configs\"))[active_speaker]\n",
    "            return ToolCallEvent(\n",
    "                tools=agent_config.tools,\n",
    "                tool_call=ToolSelection(\n",
    "                    tool_id=ev.tool_id,\n",
    "                    tool_name=ev.tool_name,\n",
    "                    tool_kwargs=ev.tool_kwargs,\n",
    "                ),\n",
    "            )\n",
    "        else:\n",
    "            return ToolCallResultEvent(\n",
    "                chat_message=ChatMessage(\n",
    "                    role=\"tool\",\n",
    "                    content=ev.response or self.default_tool_reject_str,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    @step(num_workers=4)\n",
    "    async def handle_tool_call(\n",
    "        self, ctx: Context, ev: ToolCallEvent\n",
    "    ) -> ActiveSpeakerEvent:\n",
    "        \"\"\"Handles the execution of a tool call.\"\"\"\n",
    "        tool_call = ev.tool_call\n",
    "        tools_by_name = {tool.metadata.get_name(): tool for tool in ev.tools}\n",
    "\n",
    "        tool_msg = None\n",
    "\n",
    "        tool = tools_by_name.get(tool_call.tool_name)\n",
    "        additional_kwargs = {\n",
    "            \"tool_call_id\": tool_call.tool_id,\n",
    "            \"name\": tool.metadata.get_name(),\n",
    "        }\n",
    "        if not tool:\n",
    "            tool_msg = ChatMessage(\n",
    "                role=\"tool\",\n",
    "                content=f\"Tool {tool_call.tool_name} does not exist\",\n",
    "                additional_kwargs=additional_kwargs,\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            tool_output = await tool.acall(**tool_call.tool_kwargs)\n",
    "\n",
    "            tool_msg = ChatMessage(\n",
    "                role=\"tool\",\n",
    "                content=tool_output.content,\n",
    "                additional_kwargs=additional_kwargs,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            tool_msg = ChatMessage(\n",
    "                role=\"tool\",\n",
    "                content=f\"Encountered error in tool call: {e}\",\n",
    "                additional_kwargs=additional_kwargs,\n",
    "            )\n",
    "\n",
    "        ctx.write_event_to_stream(\n",
    "            ProgressEvent(\n",
    "                msg=f\"Tool {tool_call.tool_name} called with {tool_call.tool_kwargs} returned {tool_msg.content}\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return ToolCallResultEvent(chat_message=tool_msg)\n",
    "\n",
    "    @step\n",
    "    async def aggregate_tool_results(\n",
    "        self, ctx: Context, ev: ToolCallResultEvent\n",
    "    ) -> ActiveSpeakerEvent:\n",
    "        \"\"\"Collects the results of all tool calls and updates the chat history.\"\"\"\n",
    "        num_tool_calls = await ctx.get(\"num_tool_calls\")\n",
    "        results = ctx.collect_events(ev, [ToolCallResultEvent] * num_tool_calls)\n",
    "        if not results:\n",
    "            return\n",
    "\n",
    "        chat_history = await ctx.get(\"chat_history\")\n",
    "        for result in results:\n",
    "            chat_history.append(result.chat_message)\n",
    "        await ctx.set(\"chat_history\", chat_history)\n",
    "\n",
    "        return ActiveSpeakerEvent()\n",
    "\n",
    "    @step\n",
    "    async def orchestrator(\n",
    "        self, ctx: Context, ev: OrchestratorEvent\n",
    "    ) -> ActiveSpeakerEvent | StopEvent:\n",
    "        \"\"\"Decides which agent to run next, if any.\"\"\"\n",
    "        agent_configs = await ctx.get(\"agent_configs\")\n",
    "        chat_history = await ctx.get(\"chat_history\")\n",
    "\n",
    "        agent_context_str = \"\"\n",
    "        for agent_name, agent_config in agent_configs.items():\n",
    "            agent_context_str += f\"{agent_name}: {agent_config.description}\\n\"\n",
    "\n",
    "        user_state = await ctx.get(\"user_state\")\n",
    "        user_state_str = \"\\n\".join([f\"{k}: {v}\" for k, v in user_state.items()])\n",
    "        system_prompt = self.orchestrator_prompt.format(\n",
    "            agent_context_str=agent_context_str, user_state_str=user_state_str\n",
    "        )\n",
    "\n",
    "        llm_input = [ChatMessage(role=\"system\", content=system_prompt)] + chat_history\n",
    "        llm = await ctx.get(\"llm\")\n",
    "\n",
    "        # convert the TransferToAgent pydantic model to a tool\n",
    "        tools = [transfer_to_agent_tool]\n",
    "\n",
    "        response = await llm.achat_with_tools(tools, chat_history=llm_input)\n",
    "        tool_calls = llm.get_tool_calls_from_response(\n",
    "            response, error_on_no_tool_call=False\n",
    "        )\n",
    "\n",
    "        # if no tool calls were made, the orchestrator probably needs more information\n",
    "        if len(tool_calls) == 0:\n",
    "            chat_history.append(response.message)\n",
    "            return StopEvent(\n",
    "                result={\n",
    "                    \"response\": response.message.content,\n",
    "                    \"chat_history\": chat_history,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        tool_call = tool_calls[0]\n",
    "        selected_agent = tool_call.tool_kwargs[\"agent_name\"]\n",
    "        await ctx.set(\"active_speaker\", selected_agent)\n",
    "\n",
    "        ctx.write_event_to_stream(\n",
    "            ProgressEvent(msg=f\"Transferring to agent {selected_agent}\")\n",
    "        )\n",
    "\n",
    "        return ActiveSpeakerEvent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferring to agent Addition Agent\n",
      "Tool add_two_numbers requires human approval. Approving!\n",
      "Tool add_two_numbers called with {'a': 10, 'b': 10} returned 20\n",
      "-----------\n",
      "The sum of 10 + 10 is 20.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4o\", temperature=0.3)\n",
    "workflow = ConciergeAgent(verbose=False)\n",
    "\n",
    "handler = workflow.run(\n",
    "    agent_configs=[agent_config, agent_config_2],\n",
    "    user_msg=\"What is 10 + 10?\",\n",
    "    chat_history=[],\n",
    "    initial_state={\"user_name\": \"Logan\"},\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "async for event in handler.stream_events():\n",
    "    if isinstance(event, ProgressEvent):\n",
    "        print(event.msg)\n",
    "    elif isinstance(event, ToolRequestEvent):\n",
    "        print(f\"Tool {event.tool_name} requires human approval. Approving!\")\n",
    "        # TODO: Implement your own logic to approve or reject the tool call\n",
    "        # TODO: Try to reject the tool call and see what happens!\n",
    "        handler.ctx.send_event(ToolApprovedEvent(\n",
    "            approved=True,\n",
    "            tool_name=event.tool_name,\n",
    "            tool_id=event.tool_id,\n",
    "            tool_kwargs=event.tool_kwargs,\n",
    "        ))\n",
    "\n",
    "print(\"-----------\")\n",
    "\n",
    "final_result = await handler\n",
    "print(final_result[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "\n",
    "memory = ChatMemoryBuffer.from_defaults(\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "memory.set(final_result[\"chat_history\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent is requesting a transfer. Please hold.\n",
      "Transferring to agent Multiplication Agent\n",
      "Tool multiply_two_numbers called with {'a': 212, 'b': 121} returned 25652\n",
      "-----------\n",
      "The product of 212 * 121 is 25,652.\n"
     ]
    }
   ],
   "source": [
    "handler = workflow.run(\n",
    "    # maintain the same context as the previous run, which holds the active speaker!\n",
    "    ctx=handler.ctx,\n",
    "    agent_configs=[agent_config, agent_config_2],\n",
    "    user_msg=\"What is 212 * 121?\",\n",
    "    chat_history=memory.get(),\n",
    "    initial_state={\"user_name\": \"Logan\"},\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "async for event in handler.stream_events():\n",
    "    if isinstance(event, ProgressEvent):\n",
    "        print(event.msg)\n",
    "\n",
    "print(\"-----------\")\n",
    "\n",
    "final_result = await handler\n",
    "print(final_result[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.set(final_result[\"chat_history\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent is requesting a transfer. Please hold.\n",
      "-----------\n",
      "The capital of Canada is Ottawa.\n"
     ]
    }
   ],
   "source": [
    "handler = workflow.run(\n",
    "    ctx=handler.ctx,\n",
    "    agent_configs=[agent_config, agent_config_2],\n",
    "    user_msg=\"What is the capital of Canada?\",\n",
    "    chat_history=memory.get(),\n",
    "    initial_state={\"user_name\": \"Logan\"},\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "async for event in handler.stream_events():\n",
    "    if isinstance(event, ProgressEvent):\n",
    "        print(event.msg)\n",
    "\n",
    "print(\"-----------\")\n",
    "\n",
    "final_result = await handler\n",
    "print(final_result[\"response\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mutli-agent-concierge-QdC2PJgK-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
